{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVRIA : Filtrage colllaboratif - Partie II\n",
    "\n",
    "   Ce jupyter notebook contient le code permettant la prédiction des livres susceptibles de plaire à l'utilisateur. Nous entraînons et mesurons les prédictions ici, mais vous retrouverez la mise en forme des résultats de la prédiction dans le notebook Livra_recommender_system.ipynb.\n",
    "\n",
    "   Nous avons dans un premier temps utilisé notre base de données issue du questionnaire afin de mettre en place des modèles de prédiction de thèmes, modèles basés sur des techniques de filtrage collaboratif. On a pu mesurer la perfomance des modèles et les comparer entre eux en se basant sur un type de mesure d'erreur entre les valeurs des données du set de test et les prédicions des différents modèles.\n",
    "   Maintenant, nous allons pouvoir utiliser la base de données Goodbooks-10k pour réaliser le même travail de filtrage collaboratif mais cet fois-ci la prédiction sera portée sur des livres. \n",
    "   \n",
    "* Le set de données de Goodbooks-10 :\n",
    "http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/\n",
    "\n",
    "Je précise que dans la dernière partie du notebook dataVizualisation&Cleaning_GoodBooks10k.ipynb, avons nettoyé le set de donnée \"**ratings.csv**\" que nous avons enregistré sous le nom \"**df_notes.csv**\" (cf. dossier ./data). Ainsi, nous avons gardé les livres les plus notés et les utilisateurs les plus actifs - ceux qui ont attribués le plus de notes - afin de faciliter le filtrage collaboratif et de contourner le problème de la taille du set complet qui était trop gros pour être utilisé entièrement ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies\n",
    "\n",
    "On commence par importer les librairies utilisées dans ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données\n",
    "\n",
    "Vous pouvez retrouver l'ensemble des données utilisées dans le dossier './data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier 'df_notes.csv'\n",
    "df_notes = pd.read_csv('data/df_notes.csv', sep='\\t')\n",
    "# On supprime la colonne inutile :\n",
    "del df_notes['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>143</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>143</td>\n",
       "      <td>255</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0      143      258       4\n",
       "1      143       26       4\n",
       "2      143      301       3\n",
       "3      143       18       3\n",
       "4      143       27       4\n",
       "5      143       21       4\n",
       "6      143        2       5\n",
       "7      143       23       4\n",
       "8      143       24       5\n",
       "9      143      255       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On montre un extrait des notes attribuées\n",
    "df_notes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dimensions de df_notes sont de : (721076, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Les dimensions de df_notes sont de : ' + str(df_notes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des sets d'entraînement et de test\n",
    "\n",
    "Tout comme nous l'avons fait pour les thèmes préalablement (Cf. Partie I du filtrage collaboratif), on sépare le dataset en deux sets distincts : un pour l'entraînement de notre modèle de prédiction et un pour tester ce modèle. On garde 25% des données pour le set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_notes, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif\n",
    "\n",
    "On se base toujours sur les deux mêmes modèles pour le filtrage collaboratif : le \"**memory-based**\" et le \"**model-based**\".\n",
    "\n",
    "Pour commencer, on crée une matrice utilisateur-livre pour l'entraînement du modèle de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix = np.zeros((4970,4750))\n",
    "train_data_matrix = pd.DataFrame(train_data_matrix,index=df_notes['user_id'].unique(), columns=df_notes['book_id'].unique())\n",
    "for row in train_data.itertuples():\n",
    "    train_data_matrix[row[1], row[2]] = row[3]\n",
    "train_data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ensuite une matrice utilisateur-thème pour tester le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_matrix = np.zeros((4970,4750))\n",
    "for row in test_data.itertuples():\n",
    "    test_data_matrix[row[0], row[2]] = row[3]\n",
    "test_data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif avec la méthode Memory-Based \n",
    "\n",
    "L'idée sous-jacente derrière le modèle dit \"**memory-based**\" est de calculer et d'utiliser les **similarités** entre utilisateurs et/ou items -ici les thèmes- et d'utiliser ces facteurs comme des \"poids\"  permettant la prédiction d'un thème, d'une note attribuée à un livre, ou autre. \n",
    "\n",
    "Nous allons tester les deux types de filtrage collaboratif:\n",
    "\n",
    "* Item-Item \n",
    "* Utilisateur-Item \n",
    "\n",
    "Nous utilisons le coefficient de similarité. Pour cela, nous importons la fonction \"pairwise_distances\" de Scikit-Learn. \n",
    "\n",
    "On calcule d'abord la similarité entre les utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "user_similarity_theme = pairwise.cosine_similarity(train_data_theme_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_similarity_theme[:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de la similarité entre les thèmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity_theme = pairwise.cosine_similarity(train_data_theme_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity_theme[:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une méthode pour réaliser les prédictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(choices, similarity, kind='user'):\n",
    "    \n",
    "    sum_sim = np.array([np.abs(similarity).sum(axis=1)])\n",
    "    sum_sim[sum_sim == 0] = 1    \n",
    "    if kind == 'user':\n",
    "        return similarity.dot(choices) / sum_sim.T\n",
    "    elif kind == 'item':\n",
    "        return choices.dot(similarity) / sum_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode permet de prédire les thèmes susceptibles d'intéresser un utilisateur. Soit elle prend en considération les thèmes qui lui plaisent déjà, soit elle regarde les thèmes de prédilection d'autres utilisateurs ayant donné des réponses similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction_theme = predict(train_data_theme_matrix, item_similarity_theme, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction_theme[0:5,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction_theme = predict(train_data_theme_matrix, user_similarity_theme, 'user')\n",
    "user_prediction_theme[0:5,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On mesure la performance du modèle avec le calcul de la RMSE (root-mean-square error), c'est-à-dire la racine carrée de l'erreur quadratique. Cette méthode compare les vraies réponses aux réponses prédites par notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, true_value):\n",
    "    prediction = prediction.flatten()\n",
    "    true_value = true_value.flatten()\n",
    "    return sqrt(mean_squared_error(prediction, true_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE pour la prédiction basée sur la comparaison entre les utilisateurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_CF_RMSE_theme = rmse(user_prediction_theme, test_data_theme_matrix)\n",
    "print('RMSE basée sur les utilisateurs : ', user_CF_RMSE_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_CF_RMSE_theme = rmse(item_prediction_theme, test_data_theme_matrix)\n",
    "print('RMSE basée sur les thèmes : ', item_CF_RMSE_theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif avec la méthode Model-based\n",
    "\n",
    "La même logique développée dans la partie précédente (cf. I.1 memory-based collaborative filtering) peut être utilisée dans la méthode dite \"model-based\" : les similarités entre utilisateurs et/ou items peuvent être calculées et associées à un *modèle*, et on peut ensuite utiliser ce modèle pour faire nos prédictions. \n",
    "\n",
    "Le filtrage collaboratif dit \"model-based\" repose sur la factorisation de matrice. \n",
    "\n",
    "Nous allons utiliser un algorithme \"SVD-based\" permettant de réduire les dimensions de notre set de données et de guarder les caractéristiques principales, c'est-à-dire déterminantes de nos prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On regarde la proportion d'absence de données dans notre matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_theme=round(1.0-len(dataTheme)/float(1279*14),3)\n",
    "print('The sparsity level of dataTheme is ' +  str(sparsity_theme*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Decompose the train_data_theme_matrix using the SVD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(train_data_theme_matrix, k = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Crée une matrice diagonale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_diag_matrix=np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute the rating predictions from the decomposition values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_theme = np.dot(np.dot(u, s_diag_matrix), vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the model RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "    u, s, vt = svds(train_data_theme_matrix, k = k)\n",
    "    s_diag_matrix=np.diag(s)\n",
    "    X_pred_theme = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "    print('SVD-based CF RMSE (k={}): {}'.format(k, str(rmse(X_pred_theme, test_data_theme_matrix))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA avec Scikit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe la librairie permettant la réduction de dimension de notre set de données sur les thèmes\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on détermine précisemment le nombre minimum de dimensions à garder pour préserver au moins 95% de la variance caractérisant notre set de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On détermine d, le nombre de dimensions après PCA\n",
    "pca = PCA()\n",
    "pca.fit(train_data_theme)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_*100)\n",
    "d = np.argmax(cumsum >= 95)+1\n",
    "\n",
    "# On trace la variance cumulative en fonction du nombre de dimensions\n",
    "dim=np.arange(1,15)\n",
    "plt.plot(dim, cumsum)\n",
    "axes = plt.gca()\n",
    "plt.axhline(y=95,color=\"red\")\n",
    "plt.axvline(x=13, color=\"black\", linestyle='--')\n",
    "axes.xaxis.set_ticks(range(15))\n",
    "plt.axvspan(12, 13, facecolor='#2ca02c', alpha=0.3)\n",
    "plt.title(\"Variance expliquée en fonction du nombre de dimensions\")\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Variance cumulative expliquée (%)\")\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "print ('\\n nombre de dimensions du set après PCA : ' + str(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela veut dire que l'on ne peut enlever qu'une seule dimension à notre set de données si on souhaite garder assez d'informations pour la prédiction. Cependant, comme nous pouvons le voir sur le graphique, réduire le set à 12 dimensions ne nous ferait pas dépasser de beaucoup la limite de variance cumulative généralement fixée à 95% de celle du set initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
