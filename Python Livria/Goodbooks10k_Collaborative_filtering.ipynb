{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVRIA : Système de recommandation par filtrage colllaboratif (memory based method)\n",
    "\n",
    "\n",
    "\n",
    "   Ce jupyter notebook contient le code permettant de prédire les livres susceptibles de plaire à l'utilisateur.\n",
    "\n",
    "   Nous utiliserons dans un premier temps notre base de données issue d'un questionnaire dont vous pouvez observer les résultats dans le fichier answerLivria.csv. Ce dataset est axé sur les thèmes de prédilection des utilisateurs. Nous avons déjà nettoyé et vectorisé ce set de donnée (cf. dataCleaning.ipynb) et analysé les réponses (cf. dataVizualisation.ipynb).\n",
    "   Dans un second temps, nous utiliserons la base de données Goodbooks-10k, qui a l'avantage de réunir beaucoup plus de réponses et qui comprend notamment les notes attribuées par les utilisateurs aux livres qu'ils ont lus.\n",
    "   \n",
    "* Le set de données de Goodbooks-10 :\n",
    "http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/\n",
    "\n",
    "Vous pourrez retrouver le notebook jupyter dédié au collaborative filtering pour les thèmes de livres dans le fichier Livria_Themes_Collaborative_filtering.ipynb\n",
    "\n",
    "De plus, nous allons mettre en place du filtrage collaboratif par la suite pour la prédiction (cf. notebook Goodbooks10k_Collaborative_filtering), et il serait sûrement plus judicieux comme choix de garder uniquement les utilisateurs qui ont noté au moins 5 livres.\n",
    "Maintenant, gardons uniquement les utilisateurs qui ont noté au moins 5 livres. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Filtrage collaboratif pour les thèmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies\n",
    "\n",
    "On commence par importer les librairies utilisées dans ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1555538078.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to yghennam@ensc.fr and will expire on April 16, 2020.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphlab as gl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plot data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données\n",
    "\n",
    "Vous pouvez retrouver l'ensemble des données utilisées dans le dossier './data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lecture du fichier 'df_sortie.csv' contenant les thèmes choisis  et vectorisés des réponses du questionnaire.\n",
    "dataNotes = pd.read_csv('./data/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5\n",
       "3        2     9296       5\n",
       "4        2     2318       3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On montre les premières lignes de dataTheme\n",
    "dataNotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dimensions de dataNotes sont de : (5976479, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Les dimensions de dataNotes sont de : ' + str(dataNotes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu des dimensions du tableau, il semble que le nombre de note, soit un peu moins de 6 millions, correspond avec la description faite du dataset sur le site dont vous pouvez retrouver le lien plus haut (cf. Introduction).\n",
    "\n",
    "A priori, il doit y avoir 10 000 livres notés par 53 424 utilisateurs. Vérifions-le maintenant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'utilisateurs = 53424 | Nombre de livres = 10000\n"
     ]
    }
   ],
   "source": [
    "n_users = dataNotes['user_id'].nunique()\n",
    "n_items = dataNotes['book_id'].nunique()\n",
    "print (\"Nombre d'utilisateurs = \" + str(n_users) + ' | Nombre de livres = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des sets d'entraînement et de test\n",
    "\n",
    "On sépare le dataset en deux set distincts : un pour l'entraînement de notre modèle de prédiction et un pour tester ce modèle. On garde 25% des données pour le set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_notes, test_data_notes = train_test_split(dataNotes, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif\n",
    "\n",
    "Nous allons prendre en considération deux modèle pour le filtrage collaboratif, le \"memory-based\" et le \"model-based\".\n",
    "\n",
    "D'abord, on crée une matrice utilisateur-livre pour l'entraînement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d71baeb7f4bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data_notes_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_users\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data_notes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_data_notes_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gl' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_notes_matrix = gl.SArray(np.zeros((n_users,n_items)))\n",
    "for line in train_data_notes.itertuples():\n",
    "    train_data_notes_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ensuite une matrice utilisateur-thème pour tester le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_notes_matrix = gl.SArray(np.zeros((n_users,n_items)))\n",
    "for line in test_data_notes.itertuples():\n",
    "    test_data_notes_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 Filtrage collaboratif avec la méthode Memory-Based \n",
    "\n",
    "L'idée sous-jacente derrière le modèle dit \"**memory-based**\" est de calculer et d'utiliser les **similarités** entre utilisateurs et/ou items -ici les thèmes- et d'utiliser ces facteurs comme des \"poids\"  permettant la prédiction d'un thème, d'une note attribuée à un livre, ou autre. \n",
    "\n",
    "Nous allons tester les deux types de filtrage collaboratif:\n",
    "\n",
    "* Item-Item \n",
    "* Utilisateur-Item \n",
    "\n",
    "Nous utilisons le coéfficient de similarité. Pour cela, nous importons la fonction \"pairwise_distances\" de sklearn. \n",
    "\n",
    "On calcule d'abord la similarité entre les utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "user_similarity_notes = pairwise.cosine_similarity(train_data_notes_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_similarity_theme[:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de la similarité entre les thèmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_similarity_theme = pairwise.cosine_similarity(train_data_theme_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_similarity_theme[:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une méthode pour réaliser les prédictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(choices, similarity, kind='user'):\n",
    "    \n",
    "    sum_sim = np.array([np.abs(similarity).sum(axis=1)])\n",
    "    sum_sim[sum_sim == 0] = 1    \n",
    "    if kind == 'user':\n",
    "        return similarity.dot(choices) / sum_sim.T\n",
    "    elif kind == 'item':\n",
    "        return choices.dot(similarity) / sum_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode permet de prédire les thèmes susceptibles d'intéresser un utilisateur. Soit elle prend en considération les thèmes qui lui plaisent déjà, soit elle regarde les thèmes de prédilection d'autres utilisateurs ayant donné des réponses similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_prediction_theme = predict(train_data_theme_matrix, item_similarity_theme, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_prediction_theme[0:5,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_prediction_theme = predict(train_data_theme_matrix, user_similarity_theme, 'user')\n",
    "user_prediction_theme[0:5,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On mesure la performance du modèle avec le calcul de la RMSE (root-mean-square error), c'est-à-dire la racine carrée de l'erreur quadratique. Cette méthode compare les vraies réponses aux réponses prédites par notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, true_value):\n",
    "    prediction = prediction.flatten()\n",
    "    true_value = true_value.flatten()\n",
    "    return sqrt(mean_squared_error(prediction, true_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE pour la prédiction basée sur la comparaison entre les utilisateurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_CF_RMSE_theme = rmse(user_prediction_theme, test_data_theme_matrix)\n",
    "print('RMSE basée sur les utilisateurs : ', user_CF_RMSE_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_CF_RMSE_theme = rmse(item_prediction_theme, test_data_theme_matrix)\n",
    "print('RMSE basée sur les thèmes : ', item_CF_RMSE_theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 Filtrage collaboratif avec la méthode Model-based\n",
    "\n",
    "La même logique développée dans la partie précédente (cf. I.1 memory-based collaborative filtering) peut être utilisée dans la méthode dite \"model-based\" : les similarités entre utilisateurs et/ou items peuvent être calculées et associées à un *modèle*, et on peut ensuite utiliser ce modèle pour faire nos prédictions. \n",
    "\n",
    "Le filtrage collaboratif dit \"model-based\" repose sur la factorisation de matrice. \n",
    "\n",
    "Nous allons utiliser un algorithme \"SVD-based\" permettant de réduire les dimensions de notre set de données et de guarder les caractéristiques principales, c'est-à-dire déterminantes de nos prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the sparsity of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparsity_theme=round(1.0-len(dataTheme)/float(1279*14),3)\n",
    "print('The sparsity level of dataTheme is ' +  str(sparsity_theme*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Decompose the train_data_theme_matrix using the SVD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(train_data_theme_matrix, k = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create the diagonale matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_diag_matrix=np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute the rating predictions from the decomposition values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pred_theme = np.dot(np.dot(u, s_diag_matrix), vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the model RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "    u, s, vt = svds(train_data_theme_matrix, k = k)\n",
    "    s_diag_matrix=np.diag(s)\n",
    "    X_pred_theme = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "    print('SVD-based CF RMSE (k={}): {}'.format(k, str(rmse(X_pred_theme, test_data_theme_matrix))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Filtrage collaboratif avec Goodbooks-10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lecture du fichier 'BX-Book-Ratings.csv' contenant les notes attribuées par les utilisateurs aux livres.\n",
    "dataNote = pd.read_csv('./data/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataNote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataNote.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu des dimensions du tableau, il semble que le nombre de note, soit un peu moins de 6 millions, correspond avec la description faite du dataset sur le site dont vous pouvez retrouver le lien plus haut (cf. Introduction).\n",
    "\n",
    "A priori, il doit y avoir 10 000 livres notés par 53 424 utilisateurs. Vérifions-le maintenant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = dataNote['user_id'].nunique()\n",
    "n_items = dataNote['book_id'].nunique()\n",
    "print (\"Nombre d'utilisateurs = \" + str(n_users) + ' | Nombre de livres = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des sets d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_note, test_data_note = train_test_split(dataNote, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratf \n",
    "\n",
    "D'abord, on crée une matrice utilisateur-thème pour l'entraînement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_note_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data_note.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "print(train_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
