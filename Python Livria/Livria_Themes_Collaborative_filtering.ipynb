{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVRIA : Système de recommandation par filtrage colllaboratif\n",
    "\n",
    "   Ce jupyter notebook contient le code permettant de prédire les thèmes de livres susceptibles de plaire à l'utilisateur.\n",
    "\n",
    "   Nous utiliserons dans un premier temps notre base de données issue d'un questionnaire dont vous pouvez observer les résultats dans le fichier answerLivria.csv. Ce dataset est axé sur les thèmes de prédilection des utilisateurs. Nous avons déjà nettoyé et vectorisé ce set de donnée (cf. dataCleaning.ipynb) et analysé les réponses (cf. dataVizualisation.ipynb).\n",
    "   Dans un second temps, nous utiliserons la base de données Goodbooks-10k, qui a l'avantage de réunir beaucoup plus de réponses et qui comprend notamment les notes attribuées par les utilisateurs aux livres qu'ils ont lus. \n",
    "   \n",
    "* Le set de données de Goodbooks-10 :\n",
    "http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/\n",
    "\n",
    "Vous pourrez retrouver le notebook jupyter dédié au collaborative filtering pour les livres notés de Goodbooks-10k dans le fichier Livria_Goodbooks10k_Collaborative_filtering.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies\n",
    "\n",
    "On commence par importer les librairies utilisées dans ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plot data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données\n",
    "\n",
    "Vous pouvez retrouver l'ensemble des données utilisées dans le dossier './data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier 'df_sortie.csv' contenant les thèmes choisis  et vectorisés des réponses du questionnaire.\n",
    "dataTheme = pd.read_csv('df_sortie.csv', sep='\\t')\n",
    "# On supprime la colonne inutile :\n",
    "del dataTheme['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RomanFiction</th>\n",
       "      <th>BdComics</th>\n",
       "      <th>ArtsCulture</th>\n",
       "      <th>DocMedia</th>\n",
       "      <th>Erotisme</th>\n",
       "      <th>Esoterisme</th>\n",
       "      <th>SanteBE</th>\n",
       "      <th>HistGeo</th>\n",
       "      <th>Jeunesse</th>\n",
       "      <th>LittEtrangere</th>\n",
       "      <th>ScienceTechnique</th>\n",
       "      <th>LoisirVie</th>\n",
       "      <th>SHS</th>\n",
       "      <th>Philosophie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RomanFiction  BdComics  ArtsCulture  DocMedia  Erotisme  Esoterisme  \\\n",
       "0             1         1            0         0         0           0   \n",
       "1             1         0            0         0         0           0   \n",
       "2             1         0            0         0         0           0   \n",
       "3             1         0            0         0         0           0   \n",
       "4             0         1            0         1         0           0   \n",
       "\n",
       "   SanteBE  HistGeo  Jeunesse  LittEtrangere  ScienceTechnique  LoisirVie  \\\n",
       "0        0        0         0              0                 0          0   \n",
       "1        0        0         0              1                 0          0   \n",
       "2        0        0         1              1                 0          0   \n",
       "3        0        0         0              0                 0          0   \n",
       "4        0        1         0              0                 0          0   \n",
       "\n",
       "   SHS  Philosophie  \n",
       "0    0            0  \n",
       "1    0            0  \n",
       "2    0            0  \n",
       "3    0            0  \n",
       "4    0            0  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On montre les premières lignes de dataTheme\n",
    "dataTheme.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dimensions de dataTheme sont de : (1279, 14)\n"
     ]
    }
   ],
   "source": [
    "print('Les dimensions de dataTheme sont de : ' + str(dataTheme.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des sets d'entraînement et de test\n",
    "\n",
    "On sépare le dataset en deux set distincts : un pour l'entraînement de notre modèle de prédiction et un pour tester ce modèle. On garde 25% des données pour le set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_theme, test_data_theme = train_test_split(dataTheme, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif\n",
    "\n",
    "Nous allons prendre en considération deux modèle pour le filtrage collaboratif, le \"memory-based\" et le \"model-based\".\n",
    "\n",
    "D'abord, on crée une matrice utilisateur-thème pour l'entraînement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_theme_matrix = np.zeros((1279,14))\n",
    "for line in train_data_theme.itertuples():\n",
    "    train_data_theme_matrix[line[0], :] = line[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ensuite une matrice utilisateur-thème pour tester le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_theme_matrix = np.zeros((1279,14))\n",
    "for line in test_data_theme.itertuples():\n",
    "    test_data_theme_matrix[line[0], :] = line[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif avec la méthode Memory-Based \n",
    "\n",
    "L'idée sous-jacente derrière le modèle dit \"**memory-based**\" est de calculer et d'utiliser les **similarités** entre utilisateurs et/ou items -ici les thèmes- et d'utiliser ces facteurs comme des \"poids\"  permettant la prédiction d'un thème, d'une note attribuée à un livre, ou autre. \n",
    "\n",
    "Nous allons tester les deux types de filtrage collaboratif:\n",
    "\n",
    "* Item-Item \n",
    "* Utilisateur-Item \n",
    "\n",
    "Nous utilisons le coéfficient de similarité. Pour cela, nous importons la fonction \"pairwise_distances\" de sklearn. \n",
    "\n",
    "On calcule d'abord la similarité entre les utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "user_similarity_theme = pairwise.cosine_similarity(train_data_theme_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.40824829, 0.70710678, 0.40824829],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.40824829, 0.        , 1.        , 0.57735027, 0.        ],\n",
       "       [0.70710678, 0.        , 0.57735027, 1.        , 0.        ],\n",
       "       [0.40824829, 0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity_theme[:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de la similarité entre les thèmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity_theme = pairwise.cosine_similarity(train_data_theme_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.56381179, 0.33166971, 0.35786502, 0.3181418 ],\n",
       "       [0.56381179, 1.        , 0.00516811, 0.15480849, 0.19006578],\n",
       "       [0.33166971, 0.00516811, 1.        , 0.28705467, 0.11094004],\n",
       "       [0.35786502, 0.15480849, 0.28705467, 1.        , 0.07552632],\n",
       "       [0.3181418 , 0.19006578, 0.11094004, 0.07552632, 1.        ]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity_theme[:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une méthode pour réaliser les prédictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(choices, similarity, kind='user'):\n",
    "    \n",
    "    sum_sim = np.array([np.abs(similarity).sum(axis=1)])\n",
    "    sum_sim[sum_sim == 0] = 1    \n",
    "    if kind == 'user':\n",
    "        return similarity.dot(choices) / sum_sim.T\n",
    "    elif kind == 'item':\n",
    "        return choices.dot(similarity) / sum_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode permet de prédire les thèmes susceptibles d'intéresser un utilisateur. Soit elle prend en considération les thèmes qui lui plaisent déjà, soit elle regarde les thèmes de prédilection d'autres utilisateurs ayant donné des réponses similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction_theme = predict(train_data_theme_matrix, item_similarity_theme, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25899107, 0.37554162, 0.09203992],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.34291062, 0.31434597, 0.19591343],\n",
       "       [0.16561524, 0.1353966 , 0.09062775],\n",
       "       [0.22308328, 0.3348789 , 0.15081012]])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_prediction_theme[0:5,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97855045, 0.46710068, 0.07221207],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.98606546, 0.32010754, 0.1023586 ],\n",
       "       [1.        , 0.29485011, 0.09423576],\n",
       "       [0.90381968, 0.64430962, 0.10059428]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction_theme = predict(train_data_theme_matrix, user_similarity_theme, 'user')\n",
    "user_prediction_theme[0:5,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On mesure la performance du modèle avec le calcul de la RMSE (root-mean-square error), c'est-à-dire la racine carrée de l'erreur quadratique. Cette méthode compare les vraies réponses aux réponses prédites par notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, true_value):\n",
    "    prediction = prediction.flatten()\n",
    "    true_value = true_value.flatten()\n",
    "    return sqrt(mean_squared_error(prediction, true_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE pour la prédiction basée sur la comparaison entre les utilisateurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE basée sur les utilisateurs :  0.3740093820934641\n"
     ]
    }
   ],
   "source": [
    "user_CF_RMSE_theme = rmse(user_prediction_theme, test_data_theme_matrix)\n",
    "print('RMSE basée sur les utilisateurs : ', user_CF_RMSE_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE basée sur les thèmes :  0.3573586382578174\n"
     ]
    }
   ],
   "source": [
    "item_CF_RMSE_theme = rmse(item_prediction_theme, test_data_theme_matrix)\n",
    "print('RMSE basée sur les thèmes : ', item_CF_RMSE_theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrage collaboratif avec la méthode Model-based\n",
    "\n",
    "La même logique développée dans la partie précédente (cf. I.1 memory-based collaborative filtering) peut être utilisée dans la méthode dite \"model-based\" : les similarités entre utilisateurs et/ou items peuvent être calculées et associées à un *modèle*, et on peut ensuite utiliser ce modèle pour faire nos prédictions. \n",
    "\n",
    "Le filtrage collaboratif dit \"model-based\" repose sur la factorisation de matrice. \n",
    "\n",
    "Nous allons utiliser un algorithme \"SVD-based\" permettant de réduire les dimensions de notre set de données et de guarder les caractéristiques principales, c'est-à-dire déterminantes de nos prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the sparsity of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of dataTheme is 92.9%\n"
     ]
    }
   ],
   "source": [
    "sparsity_theme=round(1.0-len(dataTheme)/float(1279*14),3)\n",
    "print('The sparsity level of dataTheme is ' +  str(sparsity_theme*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Decompose the train_data_theme_matrix using the SVD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(train_data_theme_matrix, k = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create the diagonale matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_diag_matrix=np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute the rating predictions from the decomposition values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_theme = np.dot(np.dot(u, s_diag_matrix), vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the model RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD-based CF RMSE (k=1): 0.37501837562341744\n",
      "SVD-based CF RMSE (k=2): 0.39537583550113853\n",
      "SVD-based CF RMSE (k=3): 0.41031562053890486\n",
      "SVD-based CF RMSE (k=4): 0.42240731792621994\n",
      "SVD-based CF RMSE (k=5): 0.432333958049813\n",
      "SVD-based CF RMSE (k=6): 0.44028735431214905\n",
      "SVD-based CF RMSE (k=7): 0.4477493940110138\n",
      "SVD-based CF RMSE (k=8): 0.4547903224322869\n",
      "SVD-based CF RMSE (k=9): 0.46126874907961063\n",
      "SVD-based CF RMSE (k=10): 0.46619820019591574\n",
      "SVD-based CF RMSE (k=11): 0.4707318376777333\n",
      "SVD-based CF RMSE (k=12): 0.4745585468509398\n",
      "SVD-based CF RMSE (k=13): 0.4777774873107353\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "    u, s, vt = svds(train_data_theme_matrix, k = k)\n",
    "    s_diag_matrix=np.diag(s)\n",
    "    X_pred_theme = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "    print('SVD-based CF RMSE (k={}): {}'.format(k, str(rmse(X_pred_theme, test_data_theme_matrix))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
